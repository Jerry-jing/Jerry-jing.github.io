# 一、大模型工作
## 1. SAR-HUB 方案、SSL4EO-S12 方案
- SAR-HUB 不能用，开源开一半；    
- SSL4EO-S12 下游任务都是多光谱；
硬改浪费了一天时间。
## 2 在 EuroSAT-SAR 上进行 Linear Probe
- EuroSAT-SAR：    
    - 下载路径：https://huggingface.co/datasets/wangyi111/EuroSAT-SAR        
    - 大小：64 x 64        
    - 类别：10 类       
论文中的结果给的很草率，自己验证的居然比他 paper 的高。
### 2.1 EuroSAT-SAR Linear Probe 命令
```Bash
CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2  \
/workspace/FGMAE/src/transfer_classification/linear_EU_s1_mae.py \
    --batch_size 256 \
    --epochs 50 \
    --model vit_small_patch16 \
    --finetune /data/zj/FGMAE/pretrain_pth/B2_vits16_fgmae_ep99.pth \
    --data_path /data/zj/FGMAE/dataset/EuroSAT-SAR \
    --lr 0.1 \
    --warmup_epochs 0 \
    --seed 42 \
    --weight_decay 0.001 \
    --nb_classes 10 \
    --output_dir /data/zj/FGMAE/dataset/save_dir \
    --log_dir /data/zj/FGMAE/dataset/save_dir \
    --train_frac 1.0 \
```
### 2.2 EuroSAT-SAR Linear Probe 折线图

![](https://uiuti20wa5a.feishu.cn/space/api/box/stream/download/asynccode/?code=MzkyN2YzZTE0N2FhZDZhMTE0MzhmZjZkZTc0ZWQ3Y2VfNjFtbnZxYnU5aWNoeVE5NzByaUd0MHNBSVFkVHJFd0hfVG9rZW46WDBMRGJJcjdFb20xT3d4Q0Y4dGNJOU1BbkNkXzE3MTMwNzU1Nzc6MTcxMzA3OTE3N19WNA)
### 2.3 EuroSAT-SAR Linear Probe 结果表

|数据集|model|n_parameters|epoch|lr|batch_size|ACC|aACC|loss|备注|
|---|---|---|---|---|---|---|---|---|---|
|EuroSAT-SAR|||50|0.1|64 x 4|0.807|0.799||论文中|
|EuroSAT-SAR|Vit-S|3850|50|0.1|16|0.795|0.644|0.609|还在上升|
|EuroSAT-SAR|Vit-S|3850|50|0.1|256|0.806|0.796|0.570|还在上升|
|EuroSAT-SAR|Vit-B|7690|50|0.1|256|0.822|0.817|0.613|还在上升|
|EuroSAT-SAR|Vit-L|10250|50|0.1|256|0.833|0.825|0.598|还在上升|
|EuroSAT-SAR|Vit-H|12810|50|0.1|256|0.828|0.824|0.446|还在上升|
## 3. 在 EuroSAT-SAR 上进行 Finetune
### 3.1 EuroSAT-SAR Finetune 命令

```Bash
CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2  \
/workspace/FGMAE/src/transfer_classification/linear_EU_s1_mae.py \
    --data_path /data/zj/FGMAE/dataset/EuroSAT-SAR \
    --output_dir /data/zj/FGMAE/dataset/save_dir/EuroSAT_vits_finetune \
    --log_dir /data/zj/FGMAE/dataset/save_dir/EuroSAT_vits_finetune/log \
    --model vit_small_patch16 \
    --nb_classes 10 \
    --train_frac 1.0 \
    --num_workers 10 \
    --batch_size 256 \
    --epochs 50 \
    --lr 0.01 \
    --warmup_epochs 0 \
    --seed 42 \
    --fine_tune \
    --weight_decay 0.001 \
    --finetune /data/zj/FGMAE/pretrain_pth/B2_vits16_fgmae_ep99.pth \
```

### 3.2 EuroSAT-SAR Finetune 折线图

![](https://uiuti20wa5a.feishu.cn/space/api/box/stream/download/asynccode/?code=NDZhM2I5MTVmMjA4M2FjMzA3OTA1ZTI5NjIzMzZkZmZfdGhjUzRpN25uZUlGV3ZhWEZoeHNFUmFwTFo2aFNrNHpfVG9rZW46TkZyTmJTWWRLb2lvRGd4ekJJTGNBWEVvbjFmXzE3MTMwNzU1Nzc6MTcxMzA3OTE3N19WNA)

### 3.3 EuroSAT-SAR Finetune 结果表

|数据集|model|n_parameters|epoch|lr|batch_size|ACC|aACC|loss|备注|
|---|---|---|---|---|---|---|---|---|---|
|EuroSAT-SAR|||50|0.1|64 x 4|0.859|0.854||论文中|
|EuroSAT-SAR|Vit-S|21571210|50|0.1|256|0.856|0.849|0.387|还在上升|
|EuroSAT-SAR|Vit-B|85609738|50|0.1|128|0.875|0.873|0.351|还在上升|
|EuroSAT-SAR|Vit-L|303049738|50|0.1|32|0.855|0.818|0.409|还在上升|
|EuroSAT-SAR|Vit-H|630526730|50|0.1|16|0.755|0.431|0.863|估计是参数太多导致的欠拟合|
## 4. 在 BigEarthNet-S1 上进行 Linear Probe
- BigEarthNet-S1：    
    - 官网：https://bigearth.net/        
    - 大小：73G，50 多万张图片        
    - 资料：https://git.tu-berlin.de/rsim/BigEarthNet-S1_tools、https://lhackel-tub.github.io/ConfigILM/extra/BEN_LMDB_Reader.html
### 4.1 将 BigEarthNet-S1 split 并转成 lmdb 格式
> 讨厌处理数据集！
- 得到 csv 文件
```Python
from __future__ import print_function
from datetime import datetime, timedelta
import json
import os
import argparse
import csv

parser = argparse.ArgumentParser(
    description='This script extracts the tile names and ' + 
    'their download links for the BigEarthNet image patches')
parser.add_argument('-u', '--username', dest='username', help='username ' + 
                    'of a Copernicus Open Access Hub account')
parser.add_argument('-p', '--password', dest='password', help='password ' + 
                    'of a Copernicus Open Access Hub account')
parser.add_argument('-r', '--root_folder', dest='root_folder',
                    help='root folder path contains multiple patch folders')
parser.add_argument('-o', '--out_path', dest='out_path',
                    help='file path of the output csv file whose each ' + 
                    'row contains patch name, tile name and download link')
args = parser.parse_args()

if (not args.username) or (not args.password) or (not args.out_path):
        print('ERROR: need to specify -u, -p, -u and -o arguments')
        print('INFO: For help, python extract_tile_names_and_links.py --help')
        exit()
elif args.root_folder:
    if not os.path.exists(args.root_folder):
        print('ERROR: folder', args.root_folder, 'does not exist')
        print('INFO: need to download archive first')
        exit()
    root_folder = os.path.realpath(args.root_folder)

# Checks the existence of required python packages
try:
    from sentinelsat import SentinelAPI
except ImportError:
    print('ERROR: please install sentinelsat')
    print('INFO: for how to install sentinelsat, see ' + 
    'https://github.com/sentinelsat/sentinelsat')
    exit()
try:
    from os import scandir
except ImportError:
    try:
        from scandir import scandir
    except ImportError:
        print('ERROR: Either use Python 3 or ' + 
        'install scandir package for Python 2')
        exit()

# Creates SentinelAPI object with username and password
api = SentinelAPI(args.username, args.password)

dict_iter_items = (lambda d: d.iteritems()) if hasattr(
    dict, 'iteritems') else (lambda d: iter(d.items()))
search_res = {}

# Creates resulting csv file
with open(os.path.realpath(args.out_path), 'w') as fp:
    csv_writer = csv.writer(fp)
    # Iterates over patch folders
    for folder in scandir(root_folder):
        send_query = False
        patch_folder_path = os.path.realpath(folder.path)
        patch_name = os.path.basename(patch_folder_path)
        labels_metadata_path = os.path.join(patch_folder_path, 
                            patch_name + '_labels_metadata.json')
        
        # Reads labels_metadata json file 
        with open(labels_metadata_path, 'r') as f:
            labels_metadata = json.load(f)

        scene_identifier = labels_metadata["scene_source"]
        scene_filename = scene_identifier + ".SAFE"

        if not scene_filename in search_res:
            query_kwargs = {
                'filename': scene_filename,
                'platformname': 'Sentinel-1'
            }
            results = api.query(**query_kwargs)
            link = results.popitem()[1]["link"]
            search_res[scene_filename] = link
        else:
            link = search_res[scene_filename]

        csv_writer.writerow([patch_name, scene_filename, link])
```

- 转成 lmdb 文件
```Python
def make_lmdb(dataset, lmdb_file, num_workers=6):
    loader = InfiniteDataLoader(dataset, num_workers=num_workers, collate_fn=lambda x: x[0])
    env = lmdb.open(lmdb_file, map_size=1099511627776)

    txn = env.begin(write=True)
    for index, (sample, target) in tqdm(enumerate(loader), total=len(dataset), desc='Creating LMDB'):
        sample = np.array(sample)
        obj = (sample.tobytes(), sample.shape, target.tobytes())
        txn.put(str(index).encode(), pickle.dumps(obj))
        if index % 10000 == 0:
            txn.commit()
            txn = env.begin(write=True)
    txn.commit()

    env.sync()
    env.close()
    
class Bigearthnet(Dataset):
    def __init__(self, root, split, bands=None, transform=None, target_transform=None, download=False, 
                 use_new_labels=True, normalize=False, train_list=None, val_list=None):
        self.root = Path(root)
        self.split = split
        self.bands = bands if bands is not None else RGB_BANDS
        self.transform = transform
        self.target_transform = target_transform
        self.use_new_labels = use_new_labels
        self.normalize = normalize
        self.train_list = train_list
        self.val_list = val_list

    def __getitem__(self, index):
        if self.train_list is None and self.val_list is not None:
            patch_id = self.val_list[index]
        elif self.train_list is not None and self.val_list is None:
            patch_id = self.train_list[index]
        channels = []
        for b in self.bands:
            ch = rasterio.open(self.root / patch_id / f'{patch_id}_{b}.tif').read(1)
            if self.normalize:
                ch = normalize(ch, mean=BAND_STATS['mean'][b], std=BAND_STATS['std'][b])
            ch = cv2.resize(ch, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)
            channels.append(ch)
        img = np.dstack(channels)

        with open(self.root / patch_id / f'{patch_id}_labels_metadata.json', 'r') as f:
            labels = json.load(f)['labels']
        if self.use_new_labels:
            target = self.get_multihot_new(labels)
        else:
            target = self.get_multihot_old(labels)

        if self.transform is not None:
            img = self.transform(img)
        if self.target_transform is not None:
            target = self.target_transform(target)

        return img, target

    def __len__(self):
        if self.train_list is None and self.val_list is not None:
            return len(self.val_list)
        elif self.train_list is not None and self.val_list is None:
            return len(self.train_list)

    @staticmethod
    def get_multihot_old(labels):
        target = np.zeros((len(LABELS),), dtype=np.float32)
        for label in labels:
            target[LABELS.index(label)] = 1
        return target

    @staticmethod
    def get_multihot_new(labels):
        target = np.zeros((len(NEW_LABELS),), dtype=np.float32)
        for label in labels:
            if label in GROUP_LABELS:
                target[NEW_LABELS.index(GROUP_LABELS[label])] = 1
            elif label not in set(NEW_LABELS):
                continue
            else:
                target[NEW_LABELS.index(label)] = 1
        return target

if __name__ == '__main__':
    import os
    import argparse
    from bigearthnet_dataset_seco_lmdb_s1_float32 import make_lmdb
    import time
    import torch
    from torchvision import transforms

    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', type=str, default='/data/zj/FGMAE/dataset/BigEarthNet-S1-v1.0')
    parser.add_argument('--save_dir', type=str, default='/data/zj/FGMAE/dataset/BigEarthNet-S1-v1.0__/BigEarthNet-S1_lmdb')
    # parser.add_argument('--make_lmdb_dataset', type=bool, default=False)
    parser.add_argument('--make_lmdb_dataset', type=bool, default=True)
    parser.add_argument('--download', type=bool, default=False)
    args = parser.parse_args()

    make_lmdb_dataset = args.make_lmdb_dataset
    all_bands = ['VH', 'VV']
    test_loading_time = True

    root = '/data/zj/FGMAE/dataset/BigEarthNet-S1-v1.0'
    samples = []
    for name in os.listdir(root):
        samples.append(name)

    import random
    random.shuffle(samples)
    train_size = int(0.8 * len(samples))
    val_size = 0.2 * len(samples)

    train_list = samples[:train_size]
    val_list = samples[train_size:]
    
    if make_lmdb_dataset:
    
        start_time = time.time()
        train_dataset = Bigearthnet(
            train_list=train_list,
            root=args.data_dir,
            split='train',
            bands=all_bands
        )
    
    
        make_lmdb(train_dataset, lmdb_file=os.path.join(args.save_dir, 'train_B12.lmdb'))

        val_dataset = Bigearthnet(
            val_list=val_list,
            root=args.data_dir,
            split='val',
            bands=all_bands
        )

        make_lmdb(val_dataset, lmdb_file=os.path.join(args.save_dir, 'val_B12.lmdb'))
        print('LMDB dataset created: %s seconds.' % (time.time()-start_time))
```
### 4.2 BigEarthNet-S1 Linear Probe 命令
```Bash
CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 --master_port=12345 \
/workspace/FGMAE/src/transfer_classification/linear_BE_s1_mae.py \
    --data_path /data/zj/FGMAE/dataset/BigEarthNet-S1-v1.0 \
    --output_dir /data/zj/FGMAE/dataset/save_dir/BigEarthNet_S1_vits_linear_probe \
    --log_dir /data/zj/FGMAE/dataset/save_dir/BigEarthNet_S1_vits_linear_probe/log \
    --model vit_small_patch16 \
    --nb_classes 19 \
    --train_frac 1.0 \
    --num_workers 10 \
    --batch_size 64 \
    --epochs 50 \
    --lr 0.5 \
    --warmup_epochs 0 \
    --seed 42 \
    --finetune /data/zj/FGMAE/pretrain_pth/B2_vits16_fgmae_ep99.pth \
```
### 4.3 BigEarthNet-S1 Linear Probe 折线图

![](https://uiuti20wa5a.feishu.cn/space/api/box/stream/download/asynccode/?code=YWYzMzQ1ZGM5NzY4ZDFlNzU4OTNkMTU3MTU2NjhlNjVfcGRaZ1R5Tkl3OWdkNEZPSnBzVUpCWmpTYlJId05mdFhfVG9rZW46RFRXT2JvcVFSbzY0RDl4cHBONGNUQjQybm5lXzE3MTMwNzU4Mzk6MTcxMzA3OTQzOV9WNA)
### 4.4 BigEarthNet-S1 Linear Probe 结果表

| 数据集            | model    | n_parameters | epoch | lr  | batch_size | mAP   | F1    | loss  | time     | 备注  |
| -------------- | -------- | ------------ | ----- | --- | ---------- | ----- | ----- | ----- | -------- | --- |
| BigEarthNet-S1 | 论文中没有明确说 |              | 50    | 0.5 | 64 x 4     | 0.723 | 0.622 |       |          |     |
| BigEarthNet-S1 | Vit-S    | 7315         | 50    | 0.5 | 1024       | 0.699 | 0.582 | 0.243 | 2:30:00  |     |
| BigEarthNet-S1 | Vit-B    | 14611        | 50    | 0.5 | 1024       | 0.713 | 0.590 | 0.229 | 6:40:00  |     |
| BigEarthNet-S1 | Vit-L    | 19475        | 50    | 0.5 | 1024       | 0.712 | 0.598 | 0.237 | 11:50:43 |     |
| BigEarthNet-S1 | Vit-H    |              | 50    | 0.5 | 512        |       |       |       |          |     |
## 5. 在 BigEarthNet-S1 上进行 Fintune
### 5.1 BigEarthNet-S1 Finetune 的命令

```Bash
CUDA_VISIBLE_DEVICES=2,3 python -m torch.distributed.launch --nproc_per_node=2 --master_port=12345 \
 /workspace/FGMAE/src/transfer_classification/finetune_BE_s1_mae.py \
    --data_path /data/zj/FGMAE/dataset/BigEarthNet_lmdb \
    --output_dir /data/zj/FGMAE/dataset/save_dir/BigEarthNet_S1_vits_finetune \
    --log_dir /data/zj/FGMAE/dataset/save_dir/BigEarthNet_S1_vits_finetune/log \
    --model vit_small_patch16 \
    --nb_classes 19 \
    --train_frac 1.0 \
    --num_workers 10 \
    --batch_size 256 \
    --epochs 20 \
    --warmup_epochs 3 \
    --weight_decay 0.05 \
    --accum_iter 2 \
    --blr 1e-3 \
    --layer_decay 0.75 \
    --drop_path 0.2 \
    --mixup 0.8 \
    --seed 42 \
    --fine_tune \
    --finetune /data/zj/FGMAE/pretrain_pth/B2_vits16_fgmae_ep99.pth \
```

### 5.2 BigEarthNet-S1 Finetune 折线图

![](https://uiuti20wa5a.feishu.cn/space/api/box/stream/download/asynccode/?code=NDRiOWMxNmRhMGYyY2Q0M2Y4ZDZlYzJkMzk3NjgyZDNfWDBDWGRpb0w5VjViaWJxdzE3SVNYbzgzeExEeHNFNFlfVG9rZW46WUVKNWJ2clE3b3VwRll4U25iOWM0d3ZPbnBkXzE3MTMwNzU5MDU6MTcxMzA3OTUwNV9WNA)

### 5.3 BigEarthNet-S1 Finetune 结果表

|数据集|model|n_parameters|epoch|blr|batch_size|mAP|F1|loss|time|备注|
|---|---|---|---|---|---|---|---|---|---|---|
|BigEarthNet-S1|论文中没有明确说||20|1e-3|256|0.827|0.740||||
|BigEarthNet-S1|Vit-S|21574675|20|1e-3|256|0.852|0.752|0.150|3:10:00|还在上升|
|BigEarthNet-S1|Vit-B|85616659|20|1e-3|128|0.858|0.760|0.137|4:30:00|还在上升|
|BigEarthNet-S1|Vit-L|303058963|20|1e-3|32|0.845|0.744|0.144|17:00:00|还在上升|
|BigEarthNet-S1|Vit-H||20|1e-3|||||||
## 6. 分割任务
### 6.1 分割任务数据集
- 详情表

|   |   |   |   |   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|---|---|---|---|
|数据集|波段|极化方式|类别|大小|下游任务|卫星|分辨率|论文|下载|备注|
|DFC2020（SAR部分）|C 波段|VV 和 VH|10 类|train：8152 张<br><br>val：<br><br>1972 张<br><br>test：<br><br>5128 张|语义分割|Sentinel-1|256x256<br><br>空间分辨率为 20m|[SEN12MS–ACURATEDDATASETOFGEOREFERENCEDMULTI-SPECTRAL SENTINEL-1/2 IMAGERY FORDEEPLEARNINGANDDATAFUSION](https://arxiv.org/pdf/1906.07789.pdf)|https://ieee-dataport.org/competitions/2020-ieee-grss-data-fusion-contest|DFC2020 是 SEN12MS 的一部分|

- 可视化
![](https://uiuti20wa5a.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDYxYzljZDkzOTRiZWI4NTE3YjExYWFjNGNkZGU4ZTBfMGU4YWlJYlBxZTh5OW5tckNRV3UyTldvNTh6SXhBYXNfVG9rZW46Qk1mSGI3Rzd0b05aYnB4VW1IUWNhM1RibkZiXzE3MTMwNzYwMzE6MTcxMzA3OTYzMV9WNA)
- 问题：对应的标注都是方框框，标注的不是很精细
有关 dfc 2020 比赛的报告：https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9295450、https://ieeexplore.ieee.org/document/9547215
任务是使用低分辨率、嘈杂的标签作为训练数据，训练出高分辨率的结果
![](https://uiuti20wa5a.feishu.cn/space/api/box/stream/download/asynccode/?code=YzM5ZGM4YzI5YzA5OGYzNzk1YzUyODlhM2U0MWE0MzBfb0ZQWVFrVmpkS1VGYzdaOUZ0VzhTQllaZ3A5WGNodkRfVG9rZW46UVNjWmJ4M3Q0b2VRTzh4V0twNmN5S3lGblFMXzE3MTMwNzYwMzE6MTcxMzA3OTYzMV9WNA)
### 6.2 修改分割代码
借鉴@马芹 之前的分割的一部分代码
- 搭建 linear probe 和 finetune 的基本代码框架    

```Python
def main(args):
    misc.init_distributed_mode(args)

    print('job dir: {}'.format(os.path.dirname(os.path.realpath(__file__))))
    print("{}".format(args).replace(', ', ',\n'))

    device = torch.device(args.device)

    seed = args.seed + misc.get_rank()
    torch.manual_seed(seed)
    np.random.seed(seed)

    cudnn.benchmark = True

    
    train_transforms = Compose([
            RandomResizedCrop(224,scale=(0.8,1.0)),
            RandomHorizontalFlip(),
            ToTensor()])

    val_transforms = Compose([
            Resize(256),
            CenterCrop(224),
            ToTensor(),
            ])

    dataset_train = SEN12MS(
        path='/data/zj/FGMAE/dataset/dfc2020', 
        subset="train",
        transform=train_transforms
    )

    if not args.eval:
        dataset_val = SEN12MS(
            path='/data/zj/FGMAE/dataset/dfc2020', 
            subset="val",
            transform=val_transforms
        )

    else:
        dataset_val = SEN12MS(
            path='/data/zj/FGMAE/dataset/dfc2020', 
            subset="val",
            transform=val_transforms
        )         

    dataset_test = SEN12MS(
            path='/data/zj/FGMAE/dataset/dfc2020', 
            subset="val",
            transform=val_transforms
    )
    

    if True:  # args.distributed:
        num_tasks = args.world_size
        print(misc.get_world_size())
        global_rank = misc.get_rank()
        sampler_train = torch.utils.data.DistributedSampler(
            dataset_train, shuffle=True
        )
        print("Sampler_train = %s" % str(sampler_train))
        if args.dist_eval:
            if len(dataset_val) % num_tasks != 0:
                print('Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. '
                      'This will slightly alter validation results as extra duplicate entries are added to achieve '
                      'equal num of samples per-process.')
            sampler_val = torch.utils.data.DistributedSampler(
                dataset_val, num_replicas=num_tasks, rank=global_rank, shuffle=True)  # shuffle=True to reduce monitor bias
        else:
            sampler_val = torch.utils.data.SequentialSampler(dataset_val)
        sampler_test = torch.utils.data.SequentialSampler(dataset_test)
    else:
        sampler_train = torch.utils.data.RandomSampler(dataset_train)
        sampler_val = torch.utils.data.SequentialSampler(dataset_val)
        sampler_val = torch.utils.data.SequentialSampler(dataset_val)

    if global_rank == 0 and args.log_dir is not None and not args.eval:
        os.makedirs(args.log_dir, exist_ok=True)
        log_writer = SummaryWriter(log_dir=args.log_dir)
    else:
        log_writer = None

    data_loader_train = torch.utils.data.DataLoader(
        dataset_train, sampler=sampler_train,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        pin_memory=args.pin_mem,
        drop_last=True,
    )

    data_loader_val = torch.utils.data.DataLoader(
        dataset_val, sampler=sampler_val,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        pin_memory=args.pin_mem,
        drop_last=False
    )

    data_loader_test = torch.utils.data.DataLoader(
        dataset_test, sampler=sampler_test,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        pin_memory=args.pin_mem,
        drop_last=False
    )

    model = seg_mae.__dict__[args.model](
        sem_num_class=args.nb_classes,
        global_pool=args.global_pool,
        in_chans=2
    )

    if args.finetune and not args.eval:
        checkpoint = torch.load(args.finetune, map_location='cpu')

        print("Load pre-trained checkpoint from: %s" % args.finetune)
        checkpoint_model = checkpoint['model']
        state_dict = model.backbone.state_dict()
        for k in state_dict.keys():
            if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:
                print(f"Removing key {k} from pretrained checkpoint")
                del checkpoint_model[k]
        # interpolate position embedding
        interpolate_pos_embed(model, checkpoint_model)
        # load pre-trained model
        msg = model.backbone.load_state_dict(checkpoint_model, strict=False)
        print(msg)

        if args.global_pool:
            assert set(msg.missing_keys) == {'head.weight', 'head.bias', 'fc_norm.weight', 'fc_norm.bias'}
        else:
            # assert set(msg.missing_keys) == {'head.weight', 'head.bias'}
            pass

    if not args.fine_tune:
        # freeze all but the head
        for _, p in model.named_parameters():
            p.requires_grad = False
        for _, p in model.sem_decoder.named_parameters():
            p.requires_grad = True

    model.to(device)

    model_without_ddp = model
    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print("Model = %s" % str(model_without_ddp))
    print('number of params (M): %.2f' % (n_parameters / 1.e6))

    eff_batch_size = args.batch_size * args.accum_iter * args.world_size
    
    if args.lr is None:  # only base_lr is specified
        args.lr = args.blr * eff_batch_size / 256

    print("base lr: %.2e" % (args.lr * 256 / eff_batch_size))
    print("actual lr: %.2e" % args.lr)

    print("accumulate grad iterations: %d" % args.accum_iter)
    print("effective batch size: %d" % eff_batch_size)

    if args.distributed:
        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])
        model_without_ddp = model.module

    if args.fine_tune:
        optimizer = torch.optim.SGD(model_without_ddp.parameters(), args.lr, momentum=0.9, weight_decay=args.weight_decay)

    else:
        optimizer = torch.optim.SGD(model_without_ddp.sem_decoder.parameters(), args.lr, momentum=0.9, weight_decay=args.weight_decay)
                                
    print(optimizer)
    loss_scaler = NativeScaler()

    criterion = torch.nn.CrossEntropyLoss()

    print("criterion = %s" % str(criterion))

    misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)

    if args.eval:
        test_stats = evaluate(data_loader_val, model, device, criterion)
        print(f"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc_micro']:.1f}% {test_stats['acc_macro']:.1f}% {test_stats['f1_micro']:.2f}% {test_stats['f1_macro']:.2f}%")
        exit(0)

    print(f"Start training for {args.epochs} epochs")
    start_time = time.time()
    max_accuracy = 0.0
    max_acc_epoch = 0
    max_acc_test = 0.0
    for epoch in range(args.start_epoch, args.epochs):
        if args.distributed:
            data_loader_train.sampler.set_epoch(epoch)
        train_stats = train_one_epoch(
            model, criterion, data_loader_train,
            optimizer, device, epoch, loss_scaler,
            max_norm=None,
            log_writer=log_writer,
            args=args
        )
        if args.output_dir and (epoch%20==0 or epoch + 1 == args.epochs):
            misc.save_model(
                args=args, model=model, model_without_ddp=model_without_ddp, optimizer=optimizer,
                loss_scaler=loss_scaler, epoch=epoch)

        if epoch==args.start_epoch or epoch%20==0 or (epoch + 1 == args.epochs):
            test_stats = evaluate(data_loader_val, model, device, args.nb_classes, criterion)
            print(f"mIOU of the network on the {len(dataset_val)} test images: {test_stats['mIOU']:.1f}%")
            max_accuracy = max(max_accuracy, test_stats["mIOU"])
            print(f'Max mIOU: {max_accuracy:.2f}%')

        if log_writer is not None:
            log_writer.add_scalar('perf/test_mIOU', test_stats['mIOU'], epoch)
            log_writer.add_scalar('perf/test_loss', test_stats['loss'], epoch)

        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},
                        **{f'test_{k}': v for k, v in test_stats.items()},
                        'epoch': epoch,
                        'n_parameters': n_parameters}

        if args.output_dir and misc.is_main_process():
            if log_writer is not None:
                log_writer.flush()
            with open(os.path.join(args.output_dir, "log.txt"), mode="a", encoding="utf-8") as f:
                f.write(json.dumps(log_stats) + "\n")

    total_time = time.time() - start_time
    total_time_str = str(datetime.timedelta(seconds=int(total_time)))
    print('Training time {}'.format(total_time_str))
```
- 写 Dataset   
```Python
DFC2020_CLASSES = [
    0,  # class 0 unused in both schemes
    1,
    1,
    1,
    1,
    1,
    2,
    2,
    3,  # --> will be masked if no_savanna == True
    3,  # --> will be masked if no_savanna == True
    4,
    5,
    6,  # 12 --> 6
    7,  # 13 --> 7
    6,  # 14 --> 6
    8,
    9,
    10
    ]

def load_s1(path):
    with rasterio.open(path) as data:
        s1 = data.read()
    s1 = s1.astype(np.float32)
    s1 = np.nan_to_num(s1)
    s1 = np.clip(s1, -25, 0)
    s1 /= 25
    s1 += 1
    s1 = s1.astype(np.float32)
    return s1

def get_display_channels():
    display_channels = 0
    brightness_factor = 3
    return (display_channels, brightness_factor)


def load_lc(path, no_savanna=False, igbp=True):
    with rasterio.open(path) as data:
        lc = data.read(1)

    if igbp:
        lc = np.take(DFC2020_CLASSES, lc)
    else:
        lc = lc.astype(np.int64)

    if no_savanna:
        lc[lc == 3] = 0
        lc[lc > 3] -= 1

    lc -= 1
    lc[lc == -1] = 255
    return lc

def load_sample(sample, transform, use_s1,
                no_savanna=False, igbp=True, unlabeled=False):

    img = load_s1(sample["s1"])

    if unlabeled:
        return {'image': img, 'id': sample["id"]}
    else:
        lc = load_lc(sample["lc"], no_savanna=no_savanna, igbp=igbp)
        return {'image': img, 'label': lc, 'id': sample["id"]}

def get_ninputs(use_s1):
    n_inputs = 0
    if use_s1:
        n_inputs += 2
    return n_inputs

class SEN12MS(data.Dataset):
    """PyTorch dataset class for the SEN12MS dataset"""
    # expects dataset dir as:
    #       - SEN12MS_holdOutScenes.txt
    #       - ROIsxxxx_y
    #           - lc_n
    #           - s1_n
    #           - s2_n
    #
    # SEN12SEN12MS_holdOutScenes.txt contains the subdirs for the official
    # train/val split and can be obtained from:
    #   https://github.com/MSchmitt1984/SEN12MS/blob/master/splits

    def __init__(self, path, subset="train", transform=None, no_savanna=False, use_s1=False):
        """Initialize the dataset"""

        # inizialize
        super(SEN12MS, self).__init__()

        self.use_s1 = use_s1
        self.no_savanna = no_savanna
        assert subset in ["train", "val"]

        # provide number of input channels
        self.n_inputs = get_ninputs(use_s1)

        # provide index of channel(s) suitable for previewing the input
        self.display_channels, self.brightness_factor = get_display_channels()
        self.transform = transform

        # provide number of classes
        if no_savanna:
            self.n_classes = max(DFC2020_CLASSES) - 1
            self.no_savanna = True
        else:
            self.n_classes = max(DFC2020_CLASSES)
            self.no_savanna = False

        # make sure parent dir exists
        assert os.path.exists(path)

        # find and index samples
        self.samples = []
        if subset == "train":
            # pbar = tqdm(total=162556)   # we expect 541,986 / 3 * 0.9 samples
            pbar = tqdm(total=8152)
        else:
            # pbar = tqdm(total=18106)   # we expect 541,986 / 3 * 0.1 samples
            pbar = tqdm(total=1972)
        pbar.set_description("[Load]")

 
        train_root = os.path.join(path, 'DFC_Public_Dataset')
        # compile a list of paths to all samples
        if subset == "train":
            train_list = []
            for seasonfolder in ['ROIs0000_autumn', 'ROIs0000_spring',
                                 'ROIs0000_winter', 'ROIs0000_summer']:
                train_list += [os.path.join(seasonfolder, x) for x in
                               os.listdir(os.path.join(train_root, seasonfolder))]
            train_list = [x for x in train_list if "s1_" in x]
            train_list = [x for x in train_list]
            sample_dirs = train_list # train 部分

            for folder in sample_dirs:
                s1_locations = glob.glob(os.path.join(train_root, folder, "*.tif"),
                                        recursive=True)

                # INFO there is one "broken" file in the sen12ms dataset with nan
                #      values in the s1 data. we simply ignore this specific sample
                #      at this point. id: ROIs1868_summer_xx_146_p202
                if folder == "ROIs1868_summer/s2_146":
                    broken_file = os.path.join(path, "ROIs1868_summer",
                                            "s2_146",
                                            "ROIs1868_summer_s2_146_p202.tif")
                    s1_locations.remove(broken_file)
                    pbar.write("ignored one sample because of nan values in "
                            + "the s1 data")

                for s1_loc in s1_locations:
                    lc_loc = s1_loc.replace("s1", "lc")

                    pbar.update()
                    self.samples.append({"lc": lc_loc, "s1": s1_loc,
                                        "id": os.path.basename(s1_loc)})

            pbar.close()

            # sort list of samples
            self.samples = sorted(self.samples, key=lambda i: i['id'])

            print("loaded", len(self.samples),
                "samples from the sen12ms subset", subset)

        elif subset == 'val':
            # val 中的 path
            val_root = os.path.join(path, "s1_0")
            val_list = glob.glob(os.path.join(val_root, '*.tif'))
            val_list = [os.path.abspath(file) for file in val_list]
            for folder in tqdm(val_list):
                lc_loc = folder.replace("s1", "lc")
                self.samples.append({"lc": lc_loc, "s1": folder,
                                        "id": os.path.basename(folder)})
            print("loaded", len(self.samples),
                "samples from the sen12ms subset", subset)

    def __getitem__(self, index):
        """Get a single example from the dataset"""

        # get and load sample from index file
        sample = self.samples[index]
        return load_sample(sample, self.transform, self.use_s1, no_savanna=self.no_savanna,
                           igbp=True)

    def __len__(self):
        """Get number of samples in the dataset"""
        return len(self.samples)
```
- 修改网络
```Python
class SEG_FGMAE(nn.Module):

    def __init__(
        self,
        backbone: Type[nn.Module] = VisionTransformer,
        sem_decoder: Type[nn.Module] = UPerNet,
        sem_num_classes: int = 18,
    ) -> None:

        super().__init__()
        self.backbone = backbone
        self.sem_decoder = sem_decoder
        self.sem_classes = sem_num_classes

        self.out = nn.Conv2d(self.sem_classes, self.sem_classes, 3, 1, 1)

    def forward(self, input):
        seg_size = input.shape[2:]
        multi_outs = self.backbone(input)
        outs = self.sem_decoder(multi_outs)
        outs = self.out(F.interpolate(outs, seg_size, mode='bilinear', align_corners=False))
        return outs

def seg_fgmae_s(sem_num_class=18, global_pool=False, **kwargs):
    return _build_seg_fgmae(
        img_size=256,
        patch_size=16,
        encoder_depth=12,
        encoder_embed_dim=384,
        encoder_num_heads=6,
        sem_num_class=sem_num_class,
        gloabl_pool=global_pool,
        fpn_dim=256,
        # out_indices=[3,5,7,11],
        **kwargs
    )

def _build_seg_fgmae(
        img_size,
        patch_size,
        encoder_depth,
        encoder_embed_dim,
        encoder_num_heads,
        sem_num_class,
        gloabl_pool,
        fpn_dim,
        **kwargs
):
    seg_fgmae = SEG_FGMAE(
        backbone=VisionTransformer(
            img_size=img_size,
            patch_size=patch_size,
            embed_dim=encoder_embed_dim,
            num_heads=encoder_num_heads,
            mlp_ratio=4,
            qkv_bias=True,
            norm_layer=partial(torch.nn.LayerNorm, eps=1e-6),
            depth=encoder_depth,
            global_pool=gloabl_pool,
            **kwargs
        ),
        sem_decoder=UPerNet(
            in_dim=encoder_embed_dim,
            num_class=sem_num_class,
            fpn_dim=fpn_dim
        ),
        sem_num_classes=sem_num_class,
    )
    return seg_fgmae
```
- 修改其他部分：一些格式不对的问题修改等
### 6.3 在 DFC2020 上进行微调
把上次遇到的 bug 解决掉了
- 命令    
```Bash
CUDA_VISIBLE_DEVICES=1 python -m torch.distributed.launch --nproc_per_node=1  \
/workspace/FGMAE/src/transfer_segmentation/finetune_mae.py \
    --batch_size 128 \
    --model seg_fgmae_s \
    --finetune /data/zj/FGMAE/pretrain_pth/B2_vits16_fgmae_ep99.pth \
    --data_path /data/zj/FGMAE/dataset/dfc2020 \
    --nb_classes 11 \
    --output_dir /data/zj/FGMAE/dataset/save_dir/DFC2020_S1_vits_linear_probe_dfc_ft \
    --log_dir /data/zj/FGMAE/dataset/save_dir/DFC2020_S1_vits_linear_probe_dfc_ft/log \
    --train_frac 1.0 \
    --num_workers 10 \
    --epochs 20 \
    --warmup_epochs 3 \
    --weight_decay 0.05 \
    --accum_iter 2 \
    --blr 1e-3 \
    --layer_decay 0.75 \
    --drop_path 0.2 \
    --mixup 0.8 \
    --seed 42 \
    --fine_tune \
```
- 结果表  

|实验|数据集|model|方式|n_parameters|epoch|lr|batch_size|mIOU|max_mIOU|loss|time|备注|
|---|---|---|---|---|---|---|---|---|---|---|---|---|
|0|DFC2020|论文中没有明确说|||无|无|无|0.393||无|无|可能 train 和 val 的标签是不同的|
|1|DFC2020|Vit-S|Linear Probe|4515723|50|0.1|128|0.525|0.525|0.358|0:31:17|train 和 val 的标签：lc|
|2|DFC2020|Vit-S|Linear Probe|4515723|15|0.1|128|0.295|0.303|0.32|无|train 和 val 的标签：dfc；<br><br>mIOU 波动很剧烈 学习率太大的原因|
|3|DFC2020|Vit-S|Linear Probe|4515723|15|0.01|128|0.261|0.286|0.333|无|train 和 val 的标签：dfc<br><br>mIOU 先上升后下降，波动不太剧烈|
|4|DFC2020|Vit-S|finetune|26492223|20|1e-5|8|0.729|0.729|0.248|0:24:26|train 和 val 的标签：dfc mIOU 稳定了|
|5|DFC2020|Vit-S|finetune|26492223|20|1e-5|8|0.052|0.057|0.310|无|train 的标签：lc val 的标签：dfc Loss 很正常，mIOU 上下波动|
|6|DFC2020|Vit-S|finetune|26492223|20|1e-3|8|0.056|0.065|0.586|无|train 的标签：lc val 的标签：dfc Loss 很正常，mIOU 上下波动|

在 DFC2020 上做 finetune，如果 train 和 val 的标签一样的话，学习效果就很好；如果 train 和 val 不一样的话，学习效果就很差。
###  6.4 调研其他数据集
- 数据集   

|   |   |   |   |   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|---|---|---|---|
|数据集|波段|极化方式|类别|大小|下游任务|卫星|分辨率|论文|下载|备注|
|FUSAR-Map1.0|||4 类：建筑、植被、水、道路|610 张|语义分割|GF-3|1024x1024||||
|FUSAR-Map2.0|||10 类：水、林地、植被、裸土、工业、住宅、道路、稻田、种植和人工建造|总共包含 738 个图像样本，其中 549 个用于训练，189 个用于测试|||1024x1024|||每个类别的数量极不平衡<br><br>https://arxiv.org/pdf/2401.02326.pdf使用到了|
|SpaceNet6（ SAR 部分）||HH、VV 和 HV、VH||||||[SpaceNet 6: Multi-Sensor All Weather Mapping Dataset](https://arxiv.org/pdf/2004.06500.pdf)|https://spacenet.ai/sn6-challenge/|不会处理 label，所以没用|
|OpenSARUrban|C 波段|VV 和 VH|5 种大类：commercial area、residential area、industrial area、transportation hub、others； 10 种小类：skyscraper、dense and low-rise residential building、high-rise building、villas、general residential area、industrial storage area、airport、railway、highway、vegetation|33,358个城市SAR场景的图像，覆盖了中国的21个主要城市，包括10种不同的目标区域类别、4种数据格式和2种偏振模式|语义分割|Sentinel-1|100×100|[OpenSARUrban: A Sentinel-1 SAR Image Dataset for Urban Interpretation](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8952866)|https://opensar.sjtu.edu.cn/|感觉更像是场景分类，所以没用|
# 二、比赛
