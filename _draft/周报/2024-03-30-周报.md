---
title: 2024-03-30-周报
author: Jing
date: 2024-03-30
---
# 一、训练技巧——加速读取数据
## 1. 数据的流动路径
CPU：硬盘 -> 内存
内存 -> GPU
## 2. 数据处理时间占比太多表现
> GPU 利用率在 100% 和 0% 之间波动：数据加载瓶颈、数据预处理时间太长（在 CPU 上跑的话）、batch 很小
- 打印出的时间
- GPU的占用
- CPU的占用
## 3. 数据读取
### 3.1 多进程数据加载
设置 `num_worker` 参数大于 0
> PyTorch 官方提供的方式
### 3.2 更快的图片处理库
> https://www.zhihu.com/question/356829360/answer/907832358
- Opencv 一般比 PIL 快
	- `opencv` 一般要比 `PIL` 要快（但是要注意，**PIL的[惰性加载](https://www.zhihu.com/search?q=%E6%83%B0%E6%80%A7%E5%8A%A0%E8%BD%BD&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22%3A%22answer%22%2C%22sourceId%22%3A907832358%7D)的策略使得其看上去`open`要比opencv的`imread`要快，但是实际上那并没有完全加载数据，可以对open返回的对象调用其`load()`方法，从而手动加载数据**，这时的速度才是合理的）
- jpeg 读取，可以尝试 jpeg4py
- 存 bmp 图（降低解码时间）
- MMCV 对数据读取提供了比较高效而且全面的支持
	- [MMCV 核心组件分析(三)](FileClienthttps://zhuanlan.zhihu.com/p/339190576)
- Python 中的各种 `imread` 函数实现方式和读取速度上的区别
	- https://www.zhihu.com/question/48762352
### 3.3 小图拼起来存放
降低读取次数；对于大规模小文件读取，转成单独的文件，可以选择的格式：`TFRecord` 、`recordIO` 、`hdf5`、`pth`、`n5`、`Imdb` 等
## 4. 数据预处理
- 减少每次读取数据的预处理操作，如将 `resize` 操作固定下来
- 将预处理放到 GPU 上加速：- [NVIDIA](https://github.com/NVIDIA)- [DALI](https://github.com/NVIDIA/DALI)
## 5. 有关硬件
- 读取速度慢的机械硬盘换成 `NVME` 固态
- 把内存变成硬盘，将需要的数据塞进去，加快 `io`
	- 内存映射为磁盘
# 二、MP5: A Multi-modal Open-ended Embodied System in Minecraft via Active Perception
[论文](https://arxiv.org/pdf/2312.07472.pdf)
[作者知乎](https://zhuanlan.zhihu.com/p/686000830)
和朱松纯老师的讲座不谋而合
## 1. 领域
具身智能
## 2. 应用
通往真正强人工智能的必经之路。
它的应用十分广泛：机器人技术、自动驾驶汽车等。
它使用到了多种技术：深度学习、大语言模型（LLM）、视觉传感器等
## 3. motivation
- 具身智能这项任务希望，用**类似人类的方式**解决长期开放世界任务的具体系统。
- 问题：现有方法会遇到有任务引起的 `logic-aware decomposition` 和 `context-aware execution` 的复合困难
- 解决的任务分为两种：`process dependency` 和 `context dependency`
## 4. 论文提出的方案
- 论文解决方案：提出 MP5，一个 open-ended multimodal embodied system 
- 好处：`decompose feasible sub-objectives, design sophisticated context-aware executionsituation-aware plans, perform embodied action control, with frequent communication with a goal-conditioned active perception scheme.`
- 创新点：提出了MP5—— a novel embodied system developed within Minecraft
- MP5包括 5 个交互模块：
	- Parser：将 long-horizon task 分解为一系列子问题
	- Percipient：回答有关观测到的图像的各种问题（是LoRA-enabled Multimodal LLM）
	- Planner：根据当前情况安排子目标行动顺序，并细化子目标
	- Performer：执行动作并于环境互动
	- Patroller：检查 Percipient、Planner、Performer 的响应，验证当前的计划 / 行动，或者针对潜在的更好的策略进行反馈
## 5. 效果
MP5 能够鲁棒地完成 long-horizon reasoning 和 complex context understanding 
在 diamond-level 的任务上完成 22% 的胜率，在需要 complex scene understanding 的任务中达到 91% 的胜率
## 6. 前人做到的
- 大型语言模型通过将任务分解为一些列可行的子任务，来解决 process-dependent 的问题。
	- 缺点：假设 agent 是 all-seeing 的（知道所有他们的状态和所处的环境），简化了 context-dependent challenge
	- 解决 context-dependent challenge 应该：*感知能力是开放式的、有选择性的，并给出针对不同目的定制的结果（例如任务规划和行动执行）；感知模块可以与其他模块一起兼容地调度（例如，规划和执行模块）通过统一的接口，作为一个集成的系统*
## 7. 本文工作
专门为 Minecraft 设计和训练了 MineLLM，Parser、Percipient、Planner、Performer、Patroller都是大语言模型
## 8. 感想
对我来讲很新颖（但是在 Minecraft 上做 embodied agent 已经非常常见了，看到从 2022 年就开始做这样的工作），在 Minecraft 游戏作为 embodied agent 的主体环境，搭建了一个 embodied system ，与听到的朱松纯老师做的“通通”具身智能思路相同。
但是总觉得它还有很多缺陷：Minecraft 毕竟只是一款游戏，放到现实世界中是否会有 domain adaptation 的问题；所有的部分只用 LLM 会不会忽略一些其他的信息；完成的任务单线程而且比较单一，而且准确率不是很高，不像人灵活；LLM 耗费资源很多，不像人脑比较节能。

Generalist agsssssssssssssssssss
# 三、PromptKD
[论文](https://arxiv.org/pdf/2403.02781.pdf)
[作者博客](https://zhuanlan.zhihu.com/p/684269963)
## 1. 领域
> `Prompt learning` 是一种可以将大的预训练模型，不需要完全重新训练原始模型，而迁移到下游任务的一种技术。  
> `Soft prompts`

`Prompt learning`、知识蒸馏
在做 `Prompt engineering`（`Prompt learning`），基于大模型强大的泛化能力，更好优化特定领域下游任务的一种方法。  
## 2. 前人做的
`Prompt learning` 使用稀缺的标记数据获取有效 `prompt`
## 3. Prompt learning 和 Zero-shot learning 
`Prompt learning` 分类：  
- `Text-based`
- `Visual-based`  
- `Text-based and visual-based ` 
`Zero-shot learning` 分类：  
- `Inductive ZSL`：不利用未见过类别的任何信息，去预测未见过类别的标签  
- `Transductive ZSL`：利用未见过类别的无标签数据，去预测未见过类别的标签  
## 4. 创新点
![[PromptKD.png]]
提出 `unsupervised domain prompt distillation framework`  
- 预训练一个 `CLIP` 教师模型；  
	- 使用**少量的标签数据**预训练  
- 将文本特征存储为类向量（师生共享）；  
	- `save well-trained teacher text features as class vectors for student distillation`  
- 使用 KL 散度对齐师生图像编码部分（`prompt`）  
	- 训练学生模型时，使用的是完整的未标记数据集（包含可见和未见类别的所有样本）  
- 使用教师的 `text feature` 和学生蒸馏的` img encoder`，推理得到结果  
## 5. 感想
`PromptKD `使用了知识蒸馏去做 `Prompt learning`，有关 `Prompt learning` 还是有很多没有看懂。