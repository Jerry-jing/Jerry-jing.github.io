---
title: 图像信号处理器
author: Jing
date: 2024-04-17
tags:
  - 比赛
---
> 参考：[5分钟理解相机ISP (图像信号处理) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/374450578)
> 好文！
# 1. ISP 是什么
ISP：Image Signal Process 图像信号处理，ISP 对图像质量非常重要
> 光     ->   光          ->           电       ->      图像       ->         结果
>     镜头    CMOS 传感器       成像引擎          AI（GPU）
# 2. 为什么需要 ISP
- 镜头和 Sensor 的物理缺陷（不完美），需要 ISP 模块去补偿。
- 拍摄的光线条件多样，镜头和 Sensor 需要根据环境做适应。
# 3. ISP 的处理流程
## 3.1 BLC（BlackLevel Correction）——黑电平校正
### 原因
Sensor 有漏电流
- 把镜头放入一个全黑的环境，Sensor 输出的原始数据不为 0 ；而我们希望全黑时原始数据为 0 。
### 处理原理
需要找到一个*矫正值*，所有像素值都减去这个值，得到一个矫正成功的结果。
- 一般情况下，sensor的传感器周边，还有一小部分区域是有感光器的，但是没有光透射进来。可以把这部分的传感器的信号作为矫正值，从可感光部分的信号中减去，就可获得校正后信号。
如何找这个矫正值没看懂
### 处理流程
在运行时调整，不需要依赖人工矫正。
## 3.2 LSC（Lens Shade Correction）——镜头阴影校正
### 原因
这是由于随着视场角慢慢增大，能够通过照相机镜头的斜光束将慢慢减少。导致Senor捕获的图像中间亮度高，周围边缘亮度低。
### 处理原理
首先检测出图像中间亮度比较均匀的部分，认为这部分不需要矫正，然后以此为中心，计算出周围区域需要补偿的因子（增益）。实际项目中，可以把镜头对准白色物体，检查图像四周是否有暗角。
### 处理流程
在运行前依赖人工矫正。
## 3.3 BPC(Bad Point Correction)——坏点校正
或者叫 Defect Pixel Correction(DPC)
### 原因
由于Sensor是物理器件，有坏点是难以避免的；而且使用时间长了坏点会越来越多。通过在全黑环境下观察输出的彩点和亮点，或在白色物体下观察输出的彩点和黑点，就可以看到无规律的散落在各处的坏点。
### 处理原理
第一步：检测坏点。在RGB域上做5x5的评估，如果某个点和周围的点偏离度超过阈值的点为坏点。为了防止误判，还需要更复杂的逻辑，如连续评估N帧。
第二步：纠正坏点。对找到的坏点做中值滤波，替换原来的值即可。
### 处理流程
在运行时调整，不需要依赖人工矫正。
## 3.4 Demosaic——颜色插值
### 原因
按道理sensor输出的是RGB的raw data，每个像素点都感知RGB 3个分量的数字这样最准确。但是这样需要3套感光板，而且RGB的3套数据还需要时间同步和对齐，这样成本高，难度大。
所以，我们通常采用一个叫**Bayer色彩滤波阵列**(Bayer Color Filter Array，CFA)的滤光板，放在一个感光板上。
> 参考：[色彩滤波阵列(Color Filter Array)-CSDN博客](https://blog.csdn.net/baidu_34971492/article/details/107873430)
> 色彩滤波阵列（Color Filter Array 或 Color Filter Mosaic），是像素传感器上方的一层马赛克覆层，用于采集图像的色彩信息。一般的光电传感器只能感应光的强度，不能区分光的波长（色彩），因此图像传感器需要通过色彩滤波（Color Filter）以获取像素点的色彩信息。
> Color Filter 根据波长对光线进行滤波，特定的 Color Filter 只允许特定波长的光通过。例如，最常见的 **_Bayer Filter_**，又称 **_RGGB_** Filter，图像传感器通过 Bayer Filter 获得像素点上红色（Red）、绿色（Green）和蓝色（Blue）光的强度信息，再据此通过色彩还原算法（_**Demosaicing Algorithm**_）推算像素点的色值。CFA的光谱滤波特性和色彩还原算法决定了CFA色彩采集能力。通常图像传感器的光子通带和CFA的光谱响应范围会大于可见光频谱范围，因此保证图像传感器能够捕获可见光范围内所有颜色信息。
> ![[Pasted image 20240417182012.png]]
> 发明于 **_1976_** 年的 **_Bayer Filter_** 是目前市场上用途最**广**的 CFA 配置（_**Pattern**_），Bayer Filter CFA 配置中包括 **_1_** 个红光、_**1**_ 个蓝光和 _**2**_ 个绿光滤波器（**_25% Red, 25%Blue, 50%Green_**）。由于人眼天生对于绿色比较敏感，Bayer Filter 设计绿色光通透性要好于其它两种颜色。这种处理方式相比于等同处理RGB三种颜色，它所还原出来的图像，在人眼看来，噪点更低，细节更加清晰。
> 在 _**Bayer Filter**_ 处理色彩信息时，会将 _**2x2**_ 滤波矩阵当做最基本的全色值单元，通过统计单元内 _**RGB**_ 光强度的比例，计算得出该像素点的色值，如图所示。
> ![[Bayer_Filter基本色彩单元.png]]
> 如果 CFA 的基本色彩单元按照上图示意的顺序排列，则每四个像素只有一个色值，即纵向和横向分辨率只有实际像素的一半。Bayer Filter 实际上是采用的基本色彩单元是如图下图所示叠加式分布。在图像中心位置，这种叠加式分布的色彩单元分辨率与像素分辨率一致，精度高；但在图像边缘位置，由于滤波器缺失，精度略差。
> ![[Bayer_Filter基本色彩单元.png]]
### 处理原理
![[Bayer色彩滤波阵列的结构.png]]
在补充图(b)中白色像素点的数值时，我们可以认为每个白色像素点的值，和他附近的同色点的值相近。所以，最简单的方法是内插法。
![[Bayer_demosaic.png]]
### 处理流程
在运行时调整，不需要依赖人工矫正
## 3.5 Bayer Denoise——去除噪声
### 原因
Senor的感光器件包含模拟部分，所以信号中的噪声很难避免，ADC器件本身也会引入噪声。另外，当光线较暗时，整个系统需要将信号放大，这样噪声也跟着放大。
我们在看没有经过降噪处理的图片时，会感觉到图片上浮了一层彩色雪花点。
### 处理原理
对图像进行降噪处理的传统方法有均值滤波、高斯滤波，本质是低通滤波器。
普通的高斯滤波只考虑像素的空间距离关系，这样会导致滤波后图像变得模糊，为了避免图像变模糊，就需要保持图像的边缘，这时，就还要考虑相邻像素和本像素的相似程度，对于相似度高的像素给予更高的权重，我们称这种滤波为双边滤波。
### 处理流程
部分参数可提前调校（tuning），如调整滤波强弱。
## 3.6 AWB（Automatic White Balance）——自动白平衡
### 原因
人类的视觉系统有一定的颜色恒常性特点，不会受到光源颜色的影响。实际生活中，不论是晴天、阴天、室内白炽灯或日光灯下，人们所看到的白色物体总是是白色的，这就是视觉修正的结果。人脑对物体的颜色有一定先验知识，可识别物体并且更正这种色差。
但是Sensor不具备这样的特点，比如一张白纸，在不同光线下，Sensor输出的是不同颜色，在低色温下偏黄，在高色温下偏蓝。如白炽灯照明下拍出的照片易偏黄；而在户外日光充足则拍摄出来景物也会偏蓝。
我们就需要，让不同色温光线条件下白色物体，Sensor的输出都转换为更接近白色。
### 处理原理
比较常用的WEB算法有灰度世界、完美反射法等。
灰度世界（Gray World）算法基于一个假设：平均来讲，世界是灰色的。所以，白平衡就是调整R/B增益，达到R、G、B 相等。
白平衡有3个步骤：
（1）检测色温，如果手工调节，就知道图像中什么位置是白色物体了，色温容易检测；如果是自动调节，就需要估计出（猜出）图像中的白色位置，这是最重要的一环；
实际计算中为了实时操作，减少计算量，通常选取某个特定区域(如图像中央)像素进行计算。但若图像颜色较为单一或选定区域正好落入大的色块（红光下的白墙），以上算法求得的色温会非常不准确。为此，必须根据一定的约束条件，挑选出白色像素来计算色差。
（2）计算增益，计算R和B要调整的增益；调整增益将Cb和Cr调整到0 (或接近0)的两个系数，即R=G=B。
（3）色温矫正，根据增益调整整幅图片的色温。
### 处理流程
自动校正。
## 3.7 CCM（Color Correction Matrix）——颜色校正
### 原因
Sensor图像传感器获取的图像，与人们期望的颜色有距离，必须矫正。
AWB已经将白色校准了，CCM就是用来校准除白色以外其他颜色的准确度的。
### 处理原理
一般颜色校正的过程是首先利用该图像传感器拍摄到的图像与标准图像相比较，以此来计算得到一个校正矩阵，一般情况下，对颜色进行校正的过程，都会伴随有对颜色饱和度的调整。颜色的饱和度是指色彩的纯度，某色彩的纯度越高，则其表现的就越鲜明；纯度越低，表现的则比较黯淡。
用一个3X3的CCM矩阵来校准, 其中每一列系数r1+g1+b1等于一个恒定值1。Ccm矫正最终结果可以通过拍摄**24色卡**图片然后用imatest（一款专业的图像分析软件，具有强大的图像分析和处理功能）分析来做分析参考
### 处理流程
依赖手工校正。
## 3.8 RGB Gamma——Gamma校正
### 原因
人眼不同于摄像机，接收光子来感知光线。比如：在一间小黑屋中每增加一盏灯，摄像机都能线性增加亮度。但是人眼在黑暗时增加一盏灯时感受明显，往后随着灯的个数增长人眼并不会有明显感受。
### 处理原理
Gamma编码后的图像相比于线性编码的图像，明显有更多的暗部色阶。Gamma编码刚好满足了人眼对暗部细节敏感的特性。即人眼是按照gamma < 1的曲线对输入图像进行处理的（公式f(I)=I^gamma，I为原图像素值）。
现在常用的伽马校正是利用查表法来实现的，即首先根据一个伽马值，将不同亮度范围的理想输出值在查找表中设定好，在处理图像的时候，只需要根据输入的亮度，既可以得到其理想的输出值。
### 处理流程
可手工校正Gamma参数。
## 3.9 RGBToYUV——色彩空间转换
### 原因
在YUV 色彩空间上进行彩色噪声去除、 边缘增强等更方便。
### 处理原理
YUV 是一种基本色彩空间， 人眼对亮度Y改变的敏感性远比对色彩变化大很多， 因此， 对于人眼而言， 亮度分量Y 要比色度分量U、V 重要得多。所以，只有YUV444格式的YUV数据的比例是1:1:1，其他各种格式，如YUV422，YUV420等格式，UV的数据量都小于Y，达到节省存储空间和传输带宽的目的。YUV数据的概念就是这样简单。（在编程时查一下文档，再搞清楚内存排布即可）
### 处理流程
实时计算，不需要提前调校。
## 3.10 HDR（High-Dynamic Range）——高动态范围
### 原因
自然界的中光强度很宽，而人眼对高亮，极暗环境的细节分辨能力相对较窄，而摄像头记录的范围更窄，真正的HDR技术就是记录视觉范围内高亮、极暗环境的中的细节分辨率。
为保证人眼看到的世界和显示器或者摄像头采集的图像的亮度范围相差无几，甚至更好，需要通过tone mapping，将暗处和亮出细节再现。这是一种纯粹为了视觉感受而进行的处理，并非真正的HDR。也有人称为WDR（Wide Dynamic Range）。
简而言之，宽动态技术可以使场景中特别亮的区域和特别暗的区域在最终成像中同时看清楚。
### 处理原理
主要是通过tone mapping的方法，将像素值在特别暗的区域拉高，在特别亮的区域拉低。
Tone mapping有以下几种：
1) global tone mapping
(a) 单一tone mapping曲线。对整幅图低拉高，高拉低。（缺点，蒙上一层雾感觉，因为数值压缩后往中间靠拢，局部对比度下降）
(b) 双边滤波tone mapping。在图像中局部边缘处不会进行tone mapping，以保持局部细节。
2) local tone mapping
(a) 虚拟曝光。通过多帧相加确定哪些区域是高亮区，哪些区域是低亮区。然后分区进行local tone mapping
(b) local gamma。图片分成多块，对每块进行gamma矫正。主要根据每块的亮度直方图进行动态调整gamma曲线。
### 处理流程
实时计算，且需要提前调校
### 其他
HDR或WDR仍然是手机相机重点竞争的领域，说明这个方向有长足进度，但仍然有提升空间，而且是难点。
## 3.11 Color denoise / sharpness
### 原因
主要是对YUV降噪处理，同时为了消除降噪过程中对图像细节的损失，需要对图像进行锐化处理，还原图像的相关细节。
因为在YUV色彩空间，这些处理更方便。
### 处理原理
为了抑制图像的彩色噪声， 一般采用低通滤波器进行处理。例如使用M×N的高斯低通滤波器在色度通道上进行处理。
在YUV 色彩空间上彩噪去除与边缘加强、色彩与对比度加强，中间还要进行自动曝光控制等， 然后输出YUV（或者RGB） 格式的数据， 再通过I/O 接口传输到CPU 中处理
### 处理流程
实时计算，且需要提前调校。
## 3.12 AEC（Automatic Exposure Control）——自动曝光
### 原因
不同场景下，光照的强度有着很大的差别。人眼有着自适应的能力因此可以很快的调整，使自己可以感应到合适的亮度。而图像传感器却不具有这种自适应能力，因此必须使用自动曝光功能来确保拍摄的照片获得准确的曝光从而具有合适的亮度。
### 处理原理
自动曝光的实现一般包括三个步骤：
1）光强测量。光强测量的过程是利用图像的曝光信息来获得当前光照信息的过程。可以统计图像的全部像素，也可以统计图像中间部分、也可以将图像分成不同部分且每部分赋予不同权重。
2）场景分析。场景分析是指为了获得当前光照的特殊情况而进行的处理，比如有没有**背光照射**或者**正面强光**等场景下。对这些信息的分析，可以提升图像传感器的易用性，并且能大幅度提高图像的质量，**这是自动曝光中最为关键的技术**。目前常用的场景分析的技术主要有模糊逻辑和**人工神经网络算法**。这些算法比起固定分区测光算法具有更高的可靠性，主要是因为在模糊规则制定或者神经网络的训练过程中已经考虑了各种不同光照条件。
3）曝光补偿。在完成了光强测量和场景分析之后，就要控制相应的参数使得曝光调节生效。主要是通过设定曝光时间和曝光增益来实现的。
### 处理流程
实时计算，且需要提前调校。
## 3.13 AF (Auto Focus)——自动对焦

### 处理原理
AF算法的基本步骤是先判断图像的模糊程度，通过合适的模糊度评价函数求得采集的每一副图像的评价值, 然后通过搜索算法得到一系列评价值的峰值, 最后通过电机驱动将采集设备调节到峰值所在的位置, 得到最清晰的图像。
对焦评价函数
评价函数有很多种, 主要考虑的图像因素有图像频率(清晰的图像纹理多, 高频分布较多), 还有图像的灰度分量的分布(图像对应的灰度图的分量分布范围越大,说明图像的细节较多, 反应的图像的清晰程度)
常用的搜索算法有爬山算法, 搜索窗口有黄金分割点对焦嵌套窗口等.
### 处理流程
实时计算，且需要提前调校。

有关 4 通道变成 3 通道的算法
