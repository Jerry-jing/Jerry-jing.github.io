---
title: 持续学习
author: Jing
date: 2024-04-22
tags:
  - 方向探索
---
>持续学习是否会是人工智能转变的关键，可以持续的学习新的知识而不会遗忘。
>==真正的人工智能就是高度的鲁棒性和自适应性，可以自适应动态环境。==
# 1. 持续学习
了解持续学习顶刊，看一篇综述，一篇最新的论文，综合一些指标（自己提前想）判断是否入坑

# 2. 综述
时间：2024 年
期刊：TPAMI
名称：A Comprehensive Survey of Continual Learning: Theory, Method and Application
研究意义：应对现实世界的动态，智能系统需要在整个生命周期中逐步获取、更新、积累和利用知识
问题：会受到灾难遗忘的限制，学习新任务通常会导致旧任务的性能急剧下降
==seeking to bridege the basic settings, theoretical foundations, representative methods, and practical applications.==
目前持续学习的总体目标：在资源效率的背景下，确保适当的==稳定性、可塑性之间的权衡==，==足够的任务内和任务间泛化性==。
关键词：Continual Learning, Incremental Learning, Lifelong Learning, Catastrophic Forgetting
## 2.1 introduction
- 来源：学习是智能系统适应动态环境的基础。
	- 人类和其他生物具有强大的适应性，能够不断获取、更新、积累和利用知识。
- 别称：incremental learning、lifelong learning、continual learning
- 特点：持续学习是从动态数据分布中学习。
	- 传统机器学习模型用来捕获静态数据分布。
- 主要挑战：灾难性遗忘（catastrophic forgetting），对新分布的适应通常会导致捕获旧分布的能力大大降低
	- trade-off between learning plasticity and memory stability
	- 学习可塑性和记忆稳定性之间的权衡
- 主要目的：
	- 平衡 learning plasticity 和 memory stability 之间的比例；
	- 获取强大的通用性来适应任务内部和任务之间的分布差异；
	- 保证模型更新的资源效率，最好接近于只学习新的训练样本（重新使用所有训练样本的方法就不太可行，会产生巨大的计算和存储开销）
- 在概念上的分类：
	- regularization-based approach
	- replay-based approach
	- optimization-based approach
	- representation-based approach
	- architecture-based approach
- 应用：
	- 场景复杂性：训练和测试数据可以缺少任务标识；持续学习需要对小样本、半监督甚至无监督场景有效
	- 任务特异性：进展主要集中在视觉分类，其他视觉领域如目标检测、语义分割和其他相关领域如条件生成、强化学习、自然语言处理和伦理考量暂时还没有获得很大成功。
## 2.2 the setups of continual learning
- Basic Formulation
	- 持续学习在数学中的表示
- 典型场景
	- 根据增量批次的划分和任务标识的可用性
	- Instance-Incremental Learning（IIL）：实例增量学习，所有训练样本属于同一任务，并且批量到达
	- Domain-Incremental Learning（DIL）：领域增量学习，任务具有相同的数据标签空间但有不同的输入分布。不需要任务标识
	- Task-Incremental Learning（TIL）：任务增量学习，任务具有不相交的数据标签空间。训练和测试中都提供了任务标识
	- Class-Incremental Learning（CIL）：类增量学习，任务具有不相交的数据标签空间。任务标签仅在训练中提供
	- Task-Free Continual Learning（TFCL）：无任务持续学习，任务具有不相交的数据标签空间。训练或测试中均未提供任务标识
	- Online Continual Learning（OCL）：在线持续学习，任务具有不相交的数据标签空间。每个任务的训练样本作为一次性数据流到达
	- Blurred Boundary Continual Learning（BBCL）：模糊边界持续学习，任务边界模糊，其特征是不同但重叠的数据标签空间
	- Continual Pre-training （CPT）：预训练数据按顺序到达，目标是改善下游任务的迁移效果
- 评估指标
	- 持续学习表现可以从三个方面评估：迄今为止所有任务的整体表现、旧任务的记忆稳定性和新任务的学习可塑性
	- 总性能：平均精度（AA），平均增量进度（AIA）
typical scenarios and evaluation metrics



